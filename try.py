
import numpy as np
from tkinter import Tk, filedialog, messagebox
import json
#ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ë‘ ë²¡í„° ê°„ì˜ ìœ ì‚¬ë„ )
def cos_similarty(a,b):
    result = np.dot(a,b)
    return result

# pip install langchain-core langchain-community
# pip install faiss-cpu
# pip install openai  # or use other embedding models
# pip install python-pptx openpyxl PyMuPDF
# pip install "unstructured[all-docs]"  # for PPT/Excel loader
from tkinter import Tk, filedialog
import os

from langchain_community.document_loaders import (
    PyPDFLoader,
    UnstructuredPowerPointLoader,
    UnstructuredExcelLoader,
)
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

from langchain.text_splitter import RecursiveCharacterTextSplitter

# âœ… GUIë¡œ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ
def select_multiple_files():
    root = Tk()
    root.withdraw()
    file_paths = filedialog.askopenfilenames(
        title="PDF, PPTX, XLSX íŒŒì¼ ì„ íƒ",
        filetypes=[
            ("Supported files", "*.pdf *.pptx *.xlsx"),
            ("All files", "*.*"),
        ],
    )
    return list(file_paths)

# âœ… í™•ì¥ìì— ë”°ë¥¸ LangChain Loader ì„ íƒ
def load_documents(file_paths):
    all_docs = []
    for path in file_paths:
        ext = os.path.splitext(path)[1].lower()
        if ext == ".pdf":
            loader = PyPDFLoader(path)
        elif ext == ".pptx":
            loader = UnstructuredPowerPointLoader(path)
        elif ext == ".xlsx":
            loader = UnstructuredExcelLoader(path)
        else:
            print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}")
            continue
        docs = loader.load()
        all_docs.extend(docs)
    return all_docs

# âœ… ë¬¸ì„œ ë¶„í• 
def split_documents(documents):
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    return splitter.split_documents(documents)

# âœ… ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥ (FAISS)
def embed_and_store(documents, persist_path="faiss_index"):
    embeddings = OpenAIEmbeddings()  # OpenAI API í‚¤ í•„ìš” (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY)
    vectorstore = FAISS.from_documents(documents, embeddings)
    vectorstore.save_local(persist_path)
    print(f"âœ… FAISS ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ: {persist_path}")
    return vectorstore

# âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš°
if __name__ == "__main__mm":
    file_paths = select_multiple_files()
    if not file_paths:
        print("â—íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit()

    print(f"ğŸ“‚ ì„ íƒëœ íŒŒì¼: {file_paths}")
    documents = load_documents(file_paths)
    print(f"ğŸ“„ ì´ ë¡œë”©ëœ ë¬¸ì„œ ìˆ˜: {len(documents)}")

    split_docs = split_documents(documents)
    print(f"âœ‚ï¸ ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(split_docs)}")

    embed_and_store(split_docs)



def open_file():
    # íŒŒì¼ ì„ íƒê¸° ì—´ê¸°
    root = Tk()
    root.withdraw()

    contents_path = filedialog.askopenfilename(title="TXT íŒŒì¼ ì„ íƒ", filetypes=[("TXT files", "*.txt")])

    if not contents_path:
        messagebox.showwarning("ê²½ê³ ", "ëª©ì°¨ íŒŒì¼ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    else:
        print(f"ì„ íƒí•œ íŒŒì¼ ëª… :::: {contents_path}")
        with open(contents_path, 'r', encoding='utf-8') as file:
            contents = json.load(file)
            print(f"ëª©ì°¨ ë‚´ìš© ::: {contents}")
            # return contents
    
    file_paths = filedialog.askopenfilenames(
        title="PDF, PPTX, XLSX íŒŒì¼ ì„ íƒ",
        filetypes=[
            ("Supported files", "*.pdf *.pptx *.xlsx *.docx"),
            ("All files", "*.*"),
        ],
    )

    print("ì„ íƒ ëœ íŒŒì¼ ê²½ë¡œë“¤:")
    for file_path in file_paths:
        print(file_path)

    return
    
if __name__ == "__main__1":
    import langchain_community.document_loaders as loaders
#   open_file()

if __name__ == "__main__":
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    llm = ChatOpenAI(
        openai_api_base="http://localhost:1234/v1",
        openai_api_key="lm-studio",
        model_name="exaone-3.5-2.4b-instruct",
        temperature=0.7,
    )

    result = llm.invoke("ë„ˆëŠ” ëˆ„êµ¬ë‹ˆ??")
    print(result.content)