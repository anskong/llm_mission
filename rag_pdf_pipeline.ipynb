{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258408cb",
   "metadata": {},
   "source": [
    "#### **[초기값 설정]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c86328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 읽어오기\n",
    "load_dotenv(override=True)  # .env 파일을 덮어쓰기 모드로 읽기\n",
    "\n",
    "# 환경변수 불러오기\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "print(f\"openai key values ::: {openai_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"anthropic key values ::: {anthropic_key}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "print(f\"huggingface_token::: {huggingface_token}\")  # 테스트용 (실제 서비스에서는 print 금지)\n",
    "#...ddd\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671cfc78",
   "metadata": {},
   "source": [
    "#### **0.프롬프트 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0131d4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 목차\\n1. Introdoction to 국가건강보험 심사청구시스템\\n    1.1 한국 건강보험 체계\\n        1.1.1 Governance of NHI in Korea\\n        1.1.2 HIRA’s Role in 4P Concept\\n        1.1.3 Key Strategy on Korea NHI\\n\\n    1.2  심사평가시스템 표준모델\\n    1.3 심사평가정보시스템 Vision\\n\\n2.  Service Offering\\n    2.1 DUR System\\n        2.1.1 개요\\n        2.1.2. \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 목차\n",
    "str = \"\"\"\n",
    "\n",
    "\n",
    "#목차\n",
    "1. Introdoction to 국가건강보험 심사청구시스템\n",
    "    1.1 한국 건강보험 체계\n",
    "        1.1.1 Governance of NHI in Korea\n",
    "        1.1.2 HIRA’s Role in 4P Concept\n",
    "        1.1.3 Key Strategy on Korea NHI\n",
    "    1.2 심사평가시스템 표준모델\n",
    "    1.3 심사평가정보시스템 Vision\n",
    "\n",
    "2.  Service Offering\n",
    "    2.1 DUR System\n",
    "        2.1.1 개요\n",
    "        2.1.2 흐름도\n",
    "    2.2 NHIIS System\n",
    "        2.2.1 개요\n",
    "        2.2.2 NHIIS 데이터 및 사용자그룹\n",
    "        2.2.3 건강보험 급여청구, 심사, 지급 처리 흐름\n",
    "        2.2.4 e-claim\n",
    "\n",
    "#지시\n",
    " 1.목차를 기반으로 건강보험_브로셔.ppt을 생성한다.\n",
    " 2.당신은 건강보험 업무 전문가이며 문서 작성에도 탁월한 능력을 가지고 있다.\n",
    " 3.ppt파일의 첫장은 목차로 구성한다.\n",
    " 4.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7373b",
   "metadata": {},
   "source": [
    "#### **1.PDF문서로딩 + Embedding + Vector DB 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4203de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 읽어오기\n",
    "load_dotenv(override=True)  # .env 파일을 덮어쓰기 모드로 읽기\n",
    "\n",
    "# 환경변수 불러오기\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "from pdf_full_loader import PDFFullLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#PyPDFLoader 불러오기\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. PDF 로딩 및 분할\n",
    "# loader = PDFFullLoader(\"sample.pdf\")\n",
    "# documents = loader.load()\n",
    "\n",
    "# loader = PyPDFLoader(r\"G:\\내 드라이브\\LLM-RAG-LangChain\\제안요청서_바레인.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "# 2. 임베딩\n",
    "# embedding = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small',openai_api_key=openai_key)    \n",
    "\n",
    "# 3. Chroma Vector DB |  FAISS DB 구성\n",
    "vectordb = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db\")\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
    "# faiss_db = FAISS.from_documents(chunks, embedding_model)\n",
    "# retriever = faiss_db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# 4. 질의응답\n",
    "retriever.search(\"한국 건강보험 체계의 거버넌스는 어떻게 구성되어 있나요?\")  # 질의응답 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f8475",
   "metadata": {},
   "source": [
    "#### **2.LLM 연결**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd882978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = 'exaone-3.5-2.4b-instruct',\n",
    "    openai_api_key=\"lm-studio\",\n",
    "    openai_api_base=\"http://127.0.0.1:1234/v1\",\n",
    ")\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from anthropic import Anthropic\n",
    "import httpx  \n",
    "\n",
    "# vfy_client = httpx.Client(verify=False)\n",
    "\n",
    "# # 1. 직접 Anthropic\n",
    "# client = Anthropic(api_key=anthropic_key, http_client=vfy_client)\n",
    "\n",
    "# # 2. Langchain Anthropic 모델 호출\n",
    "# llm = ChatAnthropic(\n",
    "#     model_name =\"claude-3-opus-20240229\",\n",
    "#     anthropic_api_key=anthropic_key,)\n",
    "\n",
    "# llm._client = client\n",
    "\n",
    "# chat._client._transport._pool._ssl_context.check_hostname = False\n",
    "# chat._client._transport._pool._ssl_context.verify_mode = 0  # ssl.CERT_NONE\n",
    "# llm.invoke(\"안녕~ 너를 소개해줄래?\")\n",
    "\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     retriever=retriever,  # 이건 `vectorstore.as_retriever()`와 같은 객체여야 함\n",
    "#     return_source_documents=True\n",
    "# )\n",
    "\n",
    "# result = qa_chain.invoke({\"query\": \"제안요청서에 대해 설명해줘\"})\n",
    "# print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d79505",
   "metadata": {},
   "source": [
    "#### **3. LLM 기반 목차 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "def generate_toc(llm, sample_text):\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"content\"],\n",
    "        template=\"\"\"\n",
    "        다음 문서를 바탕으로 발표용 프레젠테이션의 목차를 작성해 주세요.\n",
    "        각 항목은 한 줄씩 정리해 주세요.\n",
    "\n",
    "        {content}\n",
    "        목차 : \n",
    "        1. 사업 개요\n",
    "        2. 사업 목표\n",
    "        3. 상세 요구사항     \n",
    "        \"\"\"\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    result = chain.run(sample_text[:2000])  # 일부만 사용\n",
    "    return [line.strip() for line in result.split(\"\\n\") if line.strip()]\n",
    "\n",
    "def callme():\n",
    "    print(\"callme function called\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18357b3b",
   "metadata": {},
   "source": [
    "#### **4. 목차별 자세한 내용 생성 (Retriever 기반 RAG)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6252ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def generate_content_per_topic(llm, retriever, topics):\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "    results = {}\n",
    "    for topic in topics:\n",
    "        query = f\"프레젠테이션에서 '{topic}' 항목을 설명할 내용을 자세히 작성해 주세요.\"\n",
    "        answer = qa_chain.run(query)\n",
    "        results[topic] = answer\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3803cd",
   "metadata": {},
   "source": [
    "#### **5. PPT 생성 로직**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a8557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-pptx\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from io import BytesIO\n",
    "\n",
    "def create_ppt(topics, topic_contents):\n",
    "    prs = Presentation()\n",
    "    for topic in topics:\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "        slide.shapes.title.text = topic\n",
    "        content = topic_contents.get(topic, \"내용 준비 중\")\n",
    "        slide.placeholders[1].text = content[:1500]  # 너무 길면 PPT 에러\n",
    "\n",
    "    output_path = \"generated_ppt.pptx\"\n",
    "    prs.save(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3632c14",
   "metadata": {},
   "source": [
    "#### ***전체 실행***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2257169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문서 로딩 및 Vector DB 생성\n",
    "# loader = PDFFullLoader(r\"C:\\Users\\MOON YOUNGHO\\llm\\llm_mission\\제안요청서_바레인.pdf\",chunk_size=1000, chunk_overlap=50)\n",
    "# documents = loader.load()\n",
    "\n",
    "# embedding_model = OpenAIEmbeddings(model='text-embedding-3-small',openai_api_key=openai_key)   \n",
    "\n",
    "# vectordb = Chroma.from_documents(documents, embedding, persist_directory=\"./chroma_db\")\n",
    "# retriever = vectordb.as_retriever()\n",
    "# faiss_db = FAISS.from_documents(documents, embedding_model)\n",
    "# retriever = faiss_db.as_retriever()\n",
    "\n",
    "# 2. 목차 생성\n",
    "sample_text = \"\\n\".join(doc.page_content for doc in chunks)  # 일부 사용\n",
    "print(sample_text)\n",
    "topics = generate_toc(llm, sample_text)\n",
    "print(topics)\n",
    "\n",
    "# 3. 각 목차별 내용 생성\n",
    "topic_contents = generate_content_per_topic(llm, retriever, topics)\n",
    "print(\"22222222222\")\n",
    "\n",
    "# 4. PPT 생성\n",
    "ppt_path = create_ppt(topics, topic_contents)\n",
    "print(\"33333333\")\n",
    "\n",
    "print(f\"📊 PPT 생성 완료: {ppt_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
