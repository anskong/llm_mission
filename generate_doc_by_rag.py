### RAG Langchain ê¸°ë°˜ìœ¼ë¡œ ì‚°ì¶œë¬¼ ë¬¸ì„œë¥¼ ì½ì–´ë“¤ì¸ í›„ Vector Embbedingì˜ Retreiver  LLMì—  ì „ë‹¬í•˜ì—¬ 
#   ì‹ ê·œ ë¬¸ì„œ ëª©ì°¨ ë³„ ë‚´ìš©ì„ LLMì„ í†µí•´ ìƒì„±í•˜ê³   ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ìƒì„±í•œë‹¤. 

# pip install langchain-core langchain-community langchain-text-splitters langchain-chroma langchain-openai  faiss-cpu
# pip install langchain-huggingface sentence-transformers
# pip install openai  # or use other embedding models
# pip install python-pptx openpyxl PyMuPDF
# pip install "unstructured[all-docs]"  # for PPT/Excel loader


# 1. í™˜ê²½ë³€ìˆ˜ ì½ê¸°
import os
from dotenv import load_dotenv

import os
import json
import fitz  # PyMuPDF
import sys
from pathlib import Path
from tkinter import filedialog, Tk, simpledialog, messagebox
from pptx import Presentation
from pptx.util import Inches, Pt
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import SystemMessage,HumanMessage
from operator import itemgetter
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
# from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
# from langchain_huggingface.embeddings import HuggingFaceEmbeddings

from langchain_community.document_loaders import (
    PyPDFLoader,
    UnstructuredPowerPointLoader,
    UnstructuredExcelLoader,
    UnstructuredWordDocumentLoader
)

# from langchain_community.document_loaders import (
#     PyPDFLoader,
#     MSWordLoader,
#     MSPowerPointLoader,
#     UnstructuredExcelLoader,
# )

from langchain_openai import OpenAIEmbeddings

# í™˜ê²½ë³€ìˆ˜ ì½ì–´ì˜¤ê¸°
load_dotenv(override=True)  # .env íŒŒì¼ì„ ë®ì–´ì“°ê¸° ëª¨ë“œë¡œ ì½ê¸°

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° (LLM API KEYS)
openai_key = os.getenv("OPENAI_API_KEY")
anthropic_key = os.getenv("ANTHROPIC_API_KEY")
huggingface_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# ppt ìƒì„± í•  ëª©ì°¨ ë° ëª©ì°¨ ë³„ ì§ˆë¬¸ë“¤
# contents_temp = [
#   {"title":"ì‚¬ì—…ê°œìš” - ì¶”ì§„ë°°ê²½","question":"""
#    ë°”ë ˆì¸ ì‚¬ì—…ì˜ ì¶”ì§„ë°°ê²½ì€?
#    """},
#   {"title":"ì‚¬ì—…ê°œìš” - ì¶”ì§„ëª©í‘œ","question":"ë°”ë ˆì¸ ì‚¬ì—…ì˜ ì¶”ì§„ëª©í‘œëŠ”?"},
#   {"title":"ì œì•ˆìš”ì²­ì‚¬í•­ - ìš”êµ¬ì‚¬í•­ ì´ê´„","question":"ìš”êµ¬ì‚¬í•­ ì´ê´„í‘œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”"},
#   {"title":"ì œì•ˆìš”ì²­ì‚¬í•­ - ìš”êµ¬ì‚¬í•­ ëª©ë¡","question":"ìš”êµ¬ì‚¬í•­ ëª©ë¡í‘œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”"},
#   # {"title":"ì‚¬ì—…ê°œìš” - ì¶”ì§„ë°°ê²½","question":"ë°”ë ˆì¸ ì‚¬ì—…ì˜ ì¶”ì§„ë°°ê²½ì€?"},
# ]

# embedding_model_name = "sentence-transformers/all-MiniLM-L6-v2"
# embedding_model_name = "jhgan/ko-sroberta-multitask"
embedding_model_name = r"C:\ai_dev\ko-sroberta-multitask"

# [ì‚¬ìš©í•  LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±]

llm = ChatOpenAI(
  openai_api_base="http://localhost:1234/v1",
  openai_api_key="lm-studio",
  model_name="exaone-3.5-2.4b-instruct",
  temperature=0.7,
)

# ìµœì¢… ê²°ê³¼ë‚´ìš©ì„ ì €ì¥í•  ppt ëª…ì¹­ ë° ê²½ë¡œ
output_path = None

def main():
  # response = llm.invoke("ë„ˆëŠ” ëˆ„êµ¬ë‹ˆ?")
  # print("llm connection test ::: ",response.content)
  
  # íŒŒì¼ ì„ íƒê¸° ì—´ê¸°
  root = Tk()
  root.withdraw()

  contents_path = filedialog.askopenfilename(title="TXT íŒŒì¼ ì„ íƒ", filetypes=[("TXT files", "*.txt")])

  if not contents_path:
    messagebox.showwarning("ê²½ê³ ", "ëª©ì°¨ íŒŒì¼ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return
  else :
    print(f"ì„ íƒí•œ íŒŒì¼ ëª… :::: {contents_path}")
    # contents_path = "contents.txt"
    with open(contents_path, 'r', encoding='utf-8') as file:
        global contents
        contents = json.load(file)
        print(f"ëª©ì°¨ ë‚´ìš© ::: {contents}")


  pdf_path = filedialog.askopenfilename(title="PDF íŒŒì¼ ì„ íƒ", filetypes=[("PDF files", "*.pdf")])

  if not pdf_path:
    messagebox.showwarning("ê²½ê³ ", "PDF íŒŒì¼ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return
  else :
    print(f"ì„ íƒí•œ íŒŒì¼ ëª… :::: {pdf_path}")
  

  output_path = filedialog.asksaveasfilename(defaultextension=".pptx",
                                               filetypes=[("PowerPoint files", "*.pptx")],
                                               title="ì €ì¥í•  PPT íŒŒì¼ ì´ë¦„")
  if not output_path:
        messagebox.showwarning("ê²½ê³ ", "ì €ì¥ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
  else :
      print(f"ì €ì¥ í•  íŒŒì¼ ëª… first :::: {output_path}")


  # PDF ë¬¸ì„œ ë¡œë”© ë° chunk ë¶„í• 
  loader = PyPDFLoader(pdf_path)
  pages = loader.load()
  print(f"ë¬¸ì„œ ë¡œë”©í•œ pages ìˆ˜ :::: {len(pages)}")

  splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)
  splits = splitter.split_documents(pages)
  print(f"ë¬¸ì„œë¥¼ chunk ë¶„í• í•œ ìˆ˜ :::: {len(splits)}")

  # Vector Embedding ë° Retreiver ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  # embedding = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=openai_key)


  #HuggingfaceEmbedding í•¨ìˆ˜ë¡œ Open source ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
#   model_name = "jhgan/ko-sroberta-multitask"
  
  ko_embedding= HuggingFaceEmbeddings(
      model_name=embedding_model_name
  )

  vectorstore = FAISS.from_documents(splits, ko_embedding)
  # vector store ê²€ìƒ‰ì‹œ ìœ ì‚¬ë¬¸ì„œëŠ” 5ê°œë§Œ ë°˜í™˜í•˜ë¼
  retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
  prompt_template = ChatPromptTemplate.from_messages([
    SystemMessage("""
                  ë‹¹ì‹ ì€ ê±´ê°•ë³´í—˜ ì—…ë¬´ ì „ë¬¸ê°€ì´ë©° ë¬¸ì„œ ì‘ì„±ì—ë„ íƒì›”í•©ë‹ˆë‹¤.
                  ì œê³µë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë°”ë ˆì¸ ì œì•ˆì„œ pptë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”
                  """),
    MessagesPlaceholder("chat_history"),
    HumanMessagePromptTemplate.from_template(
        """
        ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤.\nì»¨í…ìŠ¤íŠ¸ï¼š{context}\nì§ˆë¬¸ï¼š{question}
        ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì •ë¦¬í•˜ê³  ì§ˆë¬¸ì— í‘œí•¨ ëœ ì˜ˆì‹œëŠ” ë‹µë³€ í˜•ì‹ì— ì°¸ì¡°í•˜ì„¸ìš”
        """
    )
  ])
  # ì¶œë ¥ íŒŒì„œ ì •ì˜
  parser = StrOutputParser()
  
  # 11) LCEL ê¸°ë°˜ RAG ì²´ì¸ êµ¬ì„±
  rag_chain = (
    {
        "context": itemgetter("question") | retriever | format_docs,
        "question": itemgetter("question"),
        "chat_history": itemgetter("chat_history"),
    }
    | prompt_template
    | llm
    | parser
  )

  # 12) ì²´ì¸ ì‹¤í–‰
  history = []
  # question = "ë°”ë ˆì¸ ì‚¬ì—… ì¶”ì§„ ëª©í‘œëŠ”?"
  # answer = rag_chain.invoke({"question": question, "chat_history": history})

  # 13) ì²´ì¸ ì‹¤í–‰ ë° ë¬¸ì„œ ìƒì„±
  generate_doc_from_llm(rag_chain,history,output_path)

  # 13) ê²°ê³¼ ì¶œë ¥
  # print(f"\nğŸ§  ì§ˆë¬¸: {question}")
  # print("ğŸ“ ë‹µë³€:\n", answer)


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# contentsì— ë”°ë¼ RAG ì²´ì¸ì„ ì‹¤í–‰í•˜ê³  llm ê²°ê³¼ë¥¼ slides[]ì— ì €ì¥í•˜ì—¬ ppt ìƒì„±ì— ì „ë‹¬
def generate_doc_from_llm(rag_chain,history,output_path):
  slides = []
  for content in contents:
    question = content['question']
    print(f"llm question ::: {question}")
    answer = rag_chain.invoke({"question": question, "chat_history": history})
    slides.append((content['title'],answer))
  
  print("ğŸ PPT ìƒì„± ì¤‘...")
  create_ppt(slides,output_path)
  print("âœ… ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜:", output_path)

def create_ppt(slide_contents,output_path):
    prs = Presentation()

    title_slide = prs.slides.add_slide(prs.slide_layouts[0])
    title_slide.shapes.title.text = "ëª©ì°¨"
    content = title_slide.placeholders[1].text_frame

    for idx, (title, _) in enumerate(slide_contents, 1):
        content.add_paragraph().text = f"{idx}. {title}"

    for index, (title, content_text) in enumerate(slide_contents):
        chunks = split_text_to_slides(content_text)
        for i, chunk in enumerate(chunks):
            slide = prs.slides.add_slide(prs.slide_layouts[1])
            slide_title = title if i == 0 else f"{title} (ê³„ì†)"
            slide.shapes.title.text = slide_title

            para = slide.shapes.title.text_frame.paragraphs[0]
            if para.runs:
                run = para.runs[0]
                run.font.size = Pt(18)
                run.font.name = "ë§‘ì€ ê³ ë”•"

            content_box = slide.placeholders[1]
            content_box.text = chunk
            for p in content_box.text_frame.paragraphs:
                for run in p.runs:
                    run.font.size = Pt(12)
                    run.font.name = "ë§‘ì€ ê³ ë”•"

            # matched_image = match_image_by_index(index, page_images)
            # if matched_image:
            #     slide.shapes.add_picture(matched_image, Inches(5.5), Inches(1.5), width=Inches(3))
    print(f"ì €ì¥ í•  íŒŒì¼ ëª… second :::: {output_path}")
    prs.save(output_path)    
    
def split_text_to_slides(text, max_chars=800):
    paragraphs = text.split('\n')
    slides = []
    current_slide = ""

    for para in paragraphs:
        if len(current_slide) + len(para) + 1 < max_chars:
            current_slide += para + '\n'
        else:
            slides.append(current_slide.strip())
            current_slide = para + '\n'
    if current_slide:
        slides.append(current_slide.strip())

    return slides

# âœ… GUIë¡œ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ
def select_multiple_files():
    root = Tk()
    root.withdraw()
    file_paths = filedialog.askopenfilenames(
        title="PDF, PPTX, XLSX,DOCX íŒŒì¼ ì„ íƒ",
        filetypes=[
            ("Supported files", "*.pdf *.pptx *.xlsx *.docx"),
            ("All files", "*.*"),
        ],
    )
    return list(file_paths)

# âœ… í™•ì¥ìì— ë”°ë¥¸ LangChain Loader ì„ íƒ
def load_documents(file_paths):
    all_docs = []
    for path in file_paths:
        ext = os.path.splitext(path)[1].lower()
        if ext == ".pdf":
            loader = PyPDFLoader(path)
        elif ext == ".pptx":
            loader = UnstructuredPowerPointLoader(path)
            # loader = MSWordLoader(path)
        elif ext == ".xlsx":
            loader = UnstructuredExcelLoader(path)
        elif ext == ".docx":
            loader = UnstructuredWordDocumentLoader(path)
        else:
            print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}")
            continue
        docs = loader.load()
        all_docs.extend(docs)
    return all_docs

# âœ… ë¬¸ì„œ ë¶„í• 
def split_documents(documents,chunk_size=1000, chunk_overlap=200):
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    return splitter.split_documents(documents)

# âœ… ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥ (FAISS)
def embed_and_store(documents, persist_path="faiss_index"):
    # embeddings = OpenAIEmbeddings()  # OpenAI API í‚¤ í•„ìš” (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY)
    
    # model_name = "jhgan/ko-sroberta-multitask"

    print(f"embedding_model_name ::: {embedding_model_name}")

    ko_embedding= HuggingFaceEmbeddings(
        model_name=embedding_model_name
    )

    vectorstore = FAISS.from_documents(documents, ko_embedding)
    vectorstore.save_local(persist_path)
    print(f"âœ… FAISS ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ: {persist_path}")
    return vectorstore


# âœ… (ì‚¬ìš©ìê°€ ì‘ì„±í•œ) ëª©ì°¨/ì§ˆë¬¸ íŒŒì¼ ì—´ê³  ì½ì–´ë“¤ì´ê¸°
def open_contents_file():
    root = Tk()
    root.withdraw()
    contents_path = filedialog.askopenfilename(title="TXT íŒŒì¼ ì„ íƒ", filetypes=[("TXT files", "*.txt")])
    
    if not contents_path:
        messagebox.showwarning("ê²½ê³ ", "ëª©ì°¨ íŒŒì¼ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    else:
        print(f"ì„ íƒí•œ íŒŒì¼ ëª… :::: {contents_path}")
        with open(contents_path, 'r', encoding='utf-8') as file:
            global contents
            contents = json.load(file)
            # print(f"ëª©ì°¨ ë‚´ìš© ::: {contents}")
            return contents

def select_output_path():
    root = Tk()
    root.withdraw()
    output_path_ = filedialog.asksaveasfilename(defaultextension=".pptx",
                                               filetypes=[("PowerPoint files", "*.pptx")],
                                               title="ì €ì¥í•  PPT íŒŒì¼ ì´ë¦„")
    if not output_path_:
        messagebox.showwarning("ê²½ê³ ", "ì €ì¥ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit()
    else:
        print(f"ì €ì¥ í•  íŒŒì¼ ëª… :::: {output_path_}")
        return output_path_

# âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš°
def main_workflow():
    
    print("ğŸ“‚ ëª©ì°¨ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”...")
    open_contents_file()
    print(f"ëª©ì°¨ ë‚´ìš© ::: {contents}")

    print("ğŸ“‚ ë¬¸ì„œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”...")
    file_paths = select_multiple_files()
    if not file_paths:
        print("â—íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit()
    print(f"ğŸ“‚ ì„ íƒëœ íŒŒì¼: {file_paths}")

    print("ğŸ“‚ ê²°ê³¼ë¥¼ ì €ì¥í•  PPT íŒŒì¼ ê²½ë¡œë¥¼ ì„ íƒí•˜ì„¸ìš”...")
    output_path = select_output_path()

    documents = load_documents(file_paths)
    print(f"ğŸ“„ ì´ ë¡œë”©ëœ ë¬¸ì„œ ìˆ˜: {len(documents)}")

    split_docs = split_documents(documents, chunk_size=1000, chunk_overlap=200)
    if not split_docs:
        print("â—ë¬¸ì„œ ë¶„í• ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        exit()
    print(f"âœ‚ï¸ ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(split_docs)}")

    vectorstore = embed_and_store(split_docs)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt_template = ChatPromptTemplate.from_messages([
        SystemMessage("""
                    ë‹¹ì‹ ì€ ê±´ê°•ë³´í—˜ ì—…ë¬´ ì „ë¬¸ê°€ì´ë©° ë¬¸ì„œ ì‘ì„±ì—ë„ íƒì›”í•©ë‹ˆë‹¤.
                    ì œê³µë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë°”ë ˆì¸ ì œì•ˆì„œ pptë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”
                    """),
        MessagesPlaceholder("chat_history"),
        HumanMessagePromptTemplate.from_template(
            """
            ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤.\nì»¨í…ìŠ¤íŠ¸ï¼š{context}\nì§ˆë¬¸ï¼š{question}
            ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì •ë¦¬í•˜ê³  ì§ˆë¬¸ì— í‘œí•¨ ëœ ì˜ˆì‹œëŠ” ë‹µë³€ í˜•ì‹ì— ì°¸ì¡°í•˜ì„¸ìš”
            """
        )
    ])
    # ì¶œë ¥ íŒŒì„œ ì •ì˜
    parser = StrOutputParser()
    
    # LCEL ê¸°ë°˜ RAG ì²´ì¸ êµ¬ì„±
    rag_chain = (
        {
            "context": itemgetter("question") | retriever | format_docs,
            "question": itemgetter("question"),
            "chat_history": itemgetter("chat_history"),
        }
        | prompt_template
        | llm
        | parser
    )

    # 12) ì²´ì¸ ì‹¤í–‰
    history = []
    # question = "ë°”ë ˆì¸ ì‚¬ì—… ì¶”ì§„ ëª©í‘œëŠ”?"
    # answer = rag_chain.invoke({"question": question, "chat_history": history})

    # 13) ì²´ì¸ ì‹¤í–‰ ë° ë¬¸ì„œ ìƒì„±
    generate_doc_from_llm(rag_chain,history,output_path)



if __name__ == "__main__":
    main_workflow()
    
  
# if __name__ == "__main__":
#   main()

